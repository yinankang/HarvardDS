
*** This is the data Dataset_10TA01)

y<-c(45.01,57.204,26.852,66.290,40.964,72.996,79.38,52.776,55.916,38.122,35.84,75.796,37.408,54.376,46.186,46.13,30.366,39.06)


 x1<-c(6,4,5,7,5,10,1,8,6,4,6,9,5,2,7,4,3,5)

> x2<-c(91,162,11,240,73,311,316,154,164,54,53,326,55,130,112,91,14,63)

> length(y)
[1] 18
> length(x1)
[1] 18
> length(x2)
[1] 18


> a<-lm(y~x1+x2)
> summary(a)

Call:
lm(formula = y ~ x1 + x2)

Residuals:
   Min     1Q Median     3Q    Max 
-4.137 -1.293  0.099  1.652  2.613 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 32.840494   1.254270  26.183 6.18e-14 ***
x1          -0.714656   0.224690  -3.181  0.00621 ** 
x2           0.156556   0.005084  30.793 5.66e-15 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.999 on 15 degrees of freedom
Multiple R-squared:  0.9854,    Adjusted R-squared:  0.9835 
F-statistic: 507.5 on 2 and 15 DF,  p-value: 1.677e-14

*******************************************************

summary(lm(y~x1))

Call:
lm(formula = y ~ x1)

Residuals:
    Min      1Q  Median      3Q     Max 
-22.517 -10.114  -3.912  10.009  36.884 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   40.778      9.524   4.282 0.000572 ***
x1             1.718      1.632   1.053 0.308078    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 15.51 on 16 degrees of freedom
Multiple R-squared:  0.06479,   Adjusted R-squared:  0.006334 
F-statistic: 1.108 on 1 and 16 DF,  p-value: 0.3081

********************************************************

> summary(lm(y~x2))

Call:
lm(formula = y ~ x2)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5613 -1.2858 -0.0009  1.5002  5.0092 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 29.753745   0.995533   29.89 1.82e-15 ***
x2           0.150870   0.005963   25.30 2.48e-14 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.504 on 16 degrees of freedom
Multiple R-squared:  0.9756,    Adjusted R-squared:  0.9741 
F-statistic: 640.1 on 1 and 16 DF,  p-value: 2.484e-14

************************************************************
**** Added Variable Plot**************** 

avPlot(model=lm((y~x1+x2)) variable=x1)

***************************************************************

> influence.measures(a)
Influence measures of
         lm(formula = y ~ x1 + x2) :

     dfb.1_    dfb.x1   dfb.x2   dffit cov.r   cook.d    hat inf
1   0.07050  0.130570 -0.16348  0.3386 1.010 3.73e-02 0.0778    
2   0.19961 -0.185134  0.12800  0.3115 1.113 3.25e-02 0.0925    
3  -0.53687 -0.191602  0.85793 -1.0992 0.424 2.87e-01 0.1464    
4  -0.05232  0.042471  0.10033  0.1740 1.346 1.07e-02 0.1263    
5   0.02172  0.001580 -0.01981  0.0390 1.328 5.43e-04 0.0771    
6   0.43676 -0.388843 -0.28785 -0.6493 1.652 1.43e-01 0.3623   *
7  -1.41979  2.480487 -2.40308 -3.1019 1.581 2.57e+00 0.6726   *
8  -0.13125  0.243435 -0.04715  0.3227 1.233 3.55e-02 0.1339    
9   0.01779  0.037758  0.04558  0.2230 1.122 1.69e-02 0.0623    
10 -0.04239  0.014196  0.02525 -0.0531 1.358 1.01e-03 0.0993    
11 -0.04333 -0.078695  0.12861 -0.1871 1.309 1.23e-02 0.1132    
12  0.39470 -0.284296 -0.41747 -0.6840 1.468 1.56e-01 0.3187    
13 -0.04108 -0.006853  0.04680 -0.0761 1.338 2.06e-03 0.0921    
14  0.65546 -0.640809  0.20848  0.7559 0.968 1.75e-01 0.1978    
15 -0.01752  0.088390 -0.05306  0.1382 1.315 6.73e-03 0.0989    
16  0.23986 -0.121232 -0.05748  0.2924 1.091 2.85e-02 0.0800    
17 -0.56064  0.250962  0.33074 -0.6313 0.979 1.24e-01 0.1637    
18 -0.00592 -0.000749  0.00617 -0.0108 1.344 4.17e-05 0.0849 

**********************************************************


 hatvalues((lm(y~x1+x2))

         1          2          3          4          5          6          7 
0.07783021 0.09254906 0.14642760 0.12626475 0.07709368 0.36228965 0.67260687 
         8          9         10         11         12         13         14 
0.13393637 0.06229622 0.09934471 0.11321314 0.31871292 0.09209746 0.19781518 
        15         16         17         18 
0.09889707 0.08001597 0.16369773 0.08491140 

********************************************************


cooks.distance((lm(y~x1+x2))

           1            2            3            4            5            6 
3.733377e-02 3.245265e-02 2.870972e-01 1.065825e-02 5.434219e-04 1.429723e-01 
           7            8            9           10           11           12 
2.574954e+00 3.548778e-02 1.685320e-02 1.006916e-03 1.225621e-02 1.559616e-01 
          13           14           15           16           17           18 
2.057780e-03 1.751044e-01 6.732604e-03 2.852888e-02 1.242678e-01 4.172848e-05 

***********************************************************************


> dfbetas(lm(y~x1+x2))
    (Intercept)            x1           x2
1   0.070496768  0.1305704051 -0.163479713
2   0.199610524 -0.1851336991  0.128003054
3  -0.536869575 -0.1916018166  0.857932545
4  -0.052316449  0.0424705556  0.100325277
5   0.021716157  0.0015801805 -0.019812641
6   0.436759309 -0.3888433230 -0.287852576
7  -1.419791302  2.4804869319 -2.403079321
8  -0.131247615  0.2434347530 -0.047153300
9   0.017785259  0.0377575272  0.045583618
10 -0.042390056  0.0141958799  0.025248387
11 -0.043331161 -0.0786953378  0.128611531
12  0.394697880 -0.2842958731 -0.417465985
13 -0.041075492 -0.0068526545  0.046799675
14  0.655455659 -0.6408085168  0.208481905
15 -0.017524604  0.0883902003 -0.053061297
16  0.239859661 -0.1212316400 -0.057484386
17 -0.560637531  0.2509622440  0.330737880
18 -0.005924469 -0.0007488083  0.006171913

>rstudent(lm(y~x1+x2)) # calculating studentized residuals
to check outlier cases in respect to y values.


>library(car)

> vif(lm(y~x1+x2))
      x1       x2 
1.141081 1.141081 
***********************************************
SOME USEFUL FUNCTIONS IN R

regmodel=lm(y~x) #fit a regression model

summary(regmodel) #get results from fitting the regression model

anova(regmodel) #get the ANOVA table for the regression fit

plot(regmodel) #get four plots, including normal probability plot of residuals

fits=regmodel$fitted #store the fitted values in variable named "fits"

resids=regmodel$residuals #store the residual values in a varaible named "resids"

beta1hat=regmodel$coeff[2] #assign the slope coefficient to the name "beta1hat"

confint(regmodel) #CIs for all parameters

predict.lm(regmodel, interval="confidence") #make prediction and give confidence interval
 for the mean response

predict.lm(regmodel, interval="prediction") #make prediction and give prediction interval 
for the mean response


Reduced=lm(y~x)#fit reduced model
Full=lm(y~0+as.factor(x)) #fit full model
anova(Reduced, Full) #get lack-of-fit test
boxcox(regmodel) #evaluate possible Box-Cox transformations (MASS package must be installed)
Model Selection
library(leaps) #load the leaps package
allmods = regsubsets(y~x1+x2+x3+x4, nbest=2, data=mydata) #(leaps package must be loaded), identify best two models for 1, 2, 3 predictors
summary(allmods) # get summary of best subsets
summary(allmods)$adjr2 #adjusted R^2 for some models
summary(allmods)$cp #Cp for some models
plot(allmods, scale="adjr2") # plot that identifies models
plot(allmods, scale="Cp") # plot that identifies models
fullmodel=lm(y~., data=mydata) # regress y on everything in mydata
MSE=(summary(fullmodel)$sigma)^2 # store MSE for the full model
extractAIC(lm(y~x1+x2+x3), scale=MSE) #get Cp (equivalent to AIC)
step(fullmodel, scale=MSE, direction="backward") #backward elimination
none(lm(y~1) #regress y on the constant only
step(none, scope=list(upper=fullmodel), scale=MSE) #use Cp in stepwise regression








*********************************************************************************************


Diagnostics

standresid=stdres(regmodel) #store the standardized residuals in a variable named "standresids"

stud.del.resids=rstudent(regmodel) #store the studentized deleted residuals in a variable named 
"stud.del.resids"

hatvalues(regmodel) #get the leverage values (hi)

cooks.distance(regmodel) #get Cook's distance

dfbetas(regmodel) #print all dfbetas
dfbetas(regmodel)[4,1] #dfbeta for case 4, first coefficient (i.e., b_0)
dffits(regmodel) [4] #dffits for case 4
influence(regmodel) #various influence statistics, including hat values and dfbeta (not dfbetas) values
library(car) #load the package car
vif(regmodel) #variance inflation factors
