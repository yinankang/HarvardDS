---
title: "YK_Assignment8"
author: "Yinan Kang"
date: "4/15/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r message=FALSE, warning=FALSE} 
# Packages
install.packages("dplyr")
require(dyplr)
```

# Problem 8.22 
(1) What is the meaning of Beta3? 

Response: Beta3 indicates how much higher (or lower) the response function for tool model M3 is than the one for tool model M1.  

(2) What is the meaning of Beta4 - Beta3? 

Response: Beta4 - Beta3 measures how much higher (or lower) the response function for tool models M4 is than the response function for tool models M3 for any given level of tool speed.  

(3) What is the meaning of Beta1? 

Response: Beta1 represents the effect of tool speed (X1) on tool wear (Y). 


# Problem 8.24 - Assessed Valuations
## (a) Scatterplots 
```{r, warning=FALSE, message=FALSE}
rm(list=ls())
colnames <- c("y","x1","x2") 
df <- read.table(url("http://users.stat.ufl.edu/~rrandles/sta4210/Rclassnotes/data/textdatasets/KutnerData/Chapter%20%208%20Data%20Sets/CH08PR24.txt"), header=FALSE, sep="", col.names=colnames)
n <- nrow(df) 
attach(df)

model <- lm(y~x1+x2+x1:x2)

notcorner.subset <- dplyr::filter(df,df$x2==0)
corner.subset <- dplyr::filter(df,df$x2==1)

plot(notcorner.subset$x1,notcorner.subset$y,  main="Not Corner", xlab = "assessed valuation", ylab = "selling price ($thousands)")
plot(corner.subset$x1,corner.subset$y,  main="Corner", xlab = "assessed valuation", ylab = "selling price ($thousands)") 
```

Do the potential regressions appear similar?

Analysis: From a purely visual standpoint, the two potential regressions SEEM TO BE DIFFERENT. While they would likely both have an intercept value approximately just under $65K selling price, the slope for X2=0 (non-corner) data points seem to be noticeably higher than the slope for X2=1 (corner).  

## (b) Test for identity of the regression functions (corner and non-corner)


```{r, warning=FALSE, message=FALSE}
corner.model <- lm(y~ x1 + x2 + x1:x2, data=corner.subset)
notcorner.model <- lm(y~ x1 + x2 + x1:x2, data=notcorner.subset)
anova(corner.model)
anova(notcorner.model)
```

Equation for F Statistic: 
F = [ (RSS of Reduced) - (RSS of Full) / (dfR-dfF) ] / [(RSS of Full) / dfF]  
As Corner dwellings have much less observations, it is the "Restricted" model technically  

Alternatives:  
H0: X2 is significant to model (corner status is significant)
Ha: X2 is not significant to model

Decisions:  
If F-stat <= F-crit (calculated below), conclude H0  
If F-stat > F-crit, conclude Ha  

Calculating F statistic:  
```{r}
rssr <- 248.75 
rssf <- 660.36 
dfr <- 15
dff <- 47
f.stat <- ((rssr-rssf)/(dfr-dff))/(rssf/dff) 
f.crit <- qf(0.95,63,47)

print(f.stat)
print(f.crit)
```

Conclusion: As f.stat < f.crit, we conclude H0, that X2 is significant, and MODEL SHOULD KEEP X2.  

## (c) Plot regressions
```{r, warning=FALSE, message=FALSE}
par(mfrow=c(1,2))
plot(notcorner.subset$x1,notcorner.subset$y,  main="Not Corner", xlab = "assessed valuation", ylab = "selling price ($thousands)")
mtext("Y = -126.905 + 2.776*X1",1)
abline(notcorner.model)
plot(corner.subset$x1,corner.subset$y,  main="Corner", xlab = "assessed valuation", ylab = "selling price ($thousands)") 
abline(corner.model) 
mtext("Y = -50.884 + 1.668*X1",1)
```

The Regression Equations:  
Corner:  Y = -50.884 + 1.668*X1  
Not Corner:  Y = -126.905 + 2.776*X1  

We see that the slope for non-corner dwelling is higher, that selling price rices with assessed valuation more so than in corner dwellings.   


# Problem 8.29 - Second Order  
## Inputting sets of X
```{r}
set1 <- c(1,1.5,1.1,1.3,1.9,.8,1.2,1.4) 
set2 <- c(12,1,123,17,415,71,283,38) 
```

## Calculation coefficients of correlation 
```{r}
set1.sq <- set1^2
set1.cu <- set1^3
cor(set1, set1.sq)
cor(set1, set1.cu) 

set2.sq <- set2^2
set2.cu <- set2^3 
cor(set2, set2.sq)
cor(set2, set2.cu)

```
## Summary of results  

Coefficients of Correlation in Set 1:  
X and X^2: 0.9902871  
X and X^3: 0.9659484  
x and x^2 (little x's): 0  

Coefficients of Correlation in Set 2:  
X and X^2: 0.9699782  
X and X^3: 0.9290059  
x and x^2 (little x's): 0  

Analysis: We see that there are low multicollinearity levels, and no curvature and interaction effects are needed.   


# Problem 8.36 - CDI 
```{r message=FALSE, warning=FALSE}
# Import Data
rm(list=ls())
cdi.df <- read.csv("CDI.csv") 
n <- nrow(cdi.df)

# Create X^2 (X = total population)
cdi.df$popsq <- (cdi.df$Total.Population)^2
attach(cdi.df) 

```

## (a) Fit 2nd degree model
```{r}
# Create 2nd degree model  
model <- lm(Number.Active.Physicians~Total.Population+popsq)
summary(model)
plot(model$fitted.values, model$residuals)
```

Analysis: Judging by the plot above, for the majority of fitted values, the residuals lie between -1000 and 1000, which is not outstanding, but due to the scope of the dataset, it DOES appear to show representation with the data.  

## (b) 
R-squared for the 2nd order model = 0.886

```{r}
# Fitting first order model
model1 <- lm(Number.Active.Physicians~Total.Population)
summary(model1)

```

Analysis: R-squared for 1st order is 0.884. 2nd order DID NOT significantly increase R-squared. 

## (c) 

Alternatives:  
H0: X^2 is statistically significant (helpful to model)  
Ha: X^2 is not significant and can be dropped 

Decision Rules:  
If p-value <= alpha, conclude H0  
If p-value > alpha, conclude Ha   

alpha = 0.5

```{r}
anova(model1, model)
```

As p = 0.1906 < 0.5, we fail to reject H0 and CANNOT DROP 2nd order term. 









